{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementación completa del problema de modelaje estadístico"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Escriba una clase iterable que cree los datos y los entregue en lotes de tamaño k (por defecto 32). cada vez que se le soliciten los datos, debe entregar un lote de datos de forma aleatoria."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de datos\n",
    "N = 500\n",
    "\n",
    "# Generar un conjunto de datos de muestra\n",
    "np.random.seed(0)\n",
    "x = np.random.randn(N, 2)\n",
    "y = np.random.randint(0, 2, (N, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#w = tf.Variable(np.random.randn(2, 1))\n",
    "w = tf.Variable([[-2.0], [2.0]])\n",
    "#b = tf.Variable([0.])\n",
    "b = tf.Variable([0.])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar los puntos de datos en dos grupos basados en su clase\n",
    "class_0 = x[y.ravel() == 0]\n",
    "class_1 = x[y.ravel() == 1]\n",
    "class_1 += 2.5\n",
    "\n",
    "# Recodifica la matriz de datos\n",
    "x[y.ravel() == 1] += 2.5\n",
    "\n",
    "# convierte x en un tensor constante\n",
    "x = tf.constant(x)\n",
    "y = tf.constant(y)\n",
    "\n",
    "# ajusta los tipos de datos para evitar problemas de cálculo\n",
    "w = tf.cast(w, tf.float32)\n",
    "b = tf.cast(b, tf.float32)\n",
    "x = tf.cast(x, tf.float32)\n",
    "y = tf.cast(y, tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataIterator:\n",
    "    def __init__(self, x, y, batch_size=32):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.indices = np.arange(len(x))\n",
    "        np.random.shuffle(self.indices)\n",
    "        self.current_index = 0\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        if self.current_index >= len(self.x):\n",
    "            raise StopIteration\n",
    "        \n",
    "        batch_indices = self.indices[self.current_index:self.current_index+self.batch_size]\n",
    "        batch_x = self.x[batch_indices]\n",
    "        batch_y = self.y[batch_indices]\n",
    "        \n",
    "        self.current_index += self.batch_size\n",
    "        \n",
    "        return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, loss_fn, prediction_fn, data_generator):\n",
    "        self.loss_fn = loss_fn\n",
    "        self.prediction_fn = prediction_fn\n",
    "        self.data_generator = data_generator\n",
    "    \n",
    "    def train_step(self, x, y):\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self.prediction_fn(x)\n",
    "            loss = self.loss_fn(y, y_pred)\n",
    "        grads = tape.gradient(loss, [w, b])\n",
    "        optimizer.apply_gradients(zip(grads, [w, b]))\n",
    "        accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.round(y_pred), y), tf.float32))\n",
    "        return loss, accuracy\n",
    "    \n",
    "    def fit(self, epochs):\n",
    "        losses = []\n",
    "        accuracies = []\n",
    "        for epoch in range(epochs):\n",
    "            avg_loss = 0.\n",
    "            avg_accuracy = 0.\n",
    "            for batch_x, batch_y in self.data_generator:\n",
    "                loss, accuracy = self.train_step(batch_x, batch_y)\n",
    "                avg_loss += loss / len(self.data_generator)\n",
    "                avg_accuracy += accuracy / len(self.data_generator)\n",
    "            losses.append(avg_loss)\n",
    "            accuracies.append(avg_accuracy)\n",
    "            print(\"Epoch:\", epoch, \"loss:\", avg_loss.numpy(), \"accuracy:\", avg_accuracy.numpy())\n",
    "        return losses, accuracies\n",
    "    \n",
    "    def get_parameters(self):\n",
    "        return w.numpy(), b.numpy()\n",
    "    \n",
    "    def evaluate(self, x_test, y_test):\n",
    "        y_pred = self.prediction_fn(x_test)\n",
    "        loss = self.loss_fn(y_test, y_pred)\n",
    "        accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.round(y_pred), y_test), tf.float32))\n",
    "        print(\"Evaluation - loss:\", loss.numpy(), \"accuracy:\", accuracy.numpy())\n",
    "        return loss, accuracy\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return self.prediction_fn(x)\n",
    "    \n",
    "    def plot_metrics(self, losses, accuracies):\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(losses)\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training Loss')\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(accuracies)\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.title('Training Accuracy')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = Adam()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "\n",
    "# función predictora\n",
    "def pred(x):\n",
    "    y_hat = 1 / (1 + tf.exp(-tf.add(tf.matmul(x,w),b)))\n",
    "    return y_hat\n",
    "\n",
    "# pérdida\n",
    "def loss_fn(y,y_pred):\n",
    "    loss = -tf.reduce_mean(y * tf.math.log(y_pred) + (1 - y) * tf.math.log(1 - y_pred))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Only integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got array([195,  38,  87, 268,  81, 379, 486, 178, 418, 493, 114,  90, 152,\n       146, 405, 191, 453, 108, 480, 222, 465,  52,  59,  86, 351, 291,\n        10,  14, 369,  88, 371, 122])",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39m# Entrenar el modelo durante varias épocas\u001b[39;00m\n\u001b[0;32m      6\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[1;32m----> 7\u001b[0m losses, accuracies \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mfit(epochs)\n\u001b[0;32m      9\u001b[0m \u001b[39m# Obtener los parámetros del modelo entrenado\u001b[39;00m\n\u001b[0;32m     10\u001b[0m trained_w, trained_b \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39mget_parameters()\n",
      "Cell \u001b[1;32mIn[6], line 22\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, epochs)\u001b[0m\n\u001b[0;32m     20\u001b[0m avg_loss \u001b[39m=\u001b[39m \u001b[39m0.\u001b[39m\n\u001b[0;32m     21\u001b[0m avg_accuracy \u001b[39m=\u001b[39m \u001b[39m0.\u001b[39m\n\u001b[1;32m---> 22\u001b[0m \u001b[39mfor\u001b[39;00m batch_x, batch_y \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_generator:\n\u001b[0;32m     23\u001b[0m     loss, accuracy \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_step(batch_x, batch_y)\n\u001b[0;32m     24\u001b[0m     avg_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_generator)\n",
      "Cell \u001b[1;32mIn[5], line 18\u001b[0m, in \u001b[0;36mDataIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n\u001b[0;32m     17\u001b[0m batch_indices \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_index:\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_index\u001b[39m+\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size]\n\u001b[1;32m---> 18\u001b[0m batch_x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx[batch_indices]\n\u001b[0;32m     19\u001b[0m batch_y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my[batch_indices]\n\u001b[0;32m     21\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_index \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\anaconda4\\envs\\NN_time_series\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\anaconda4\\envs\\NN_time_series\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:906\u001b[0m, in \u001b[0;36m_check_index\u001b[1;34m(idx)\u001b[0m\n\u001b[0;32m    901\u001b[0m dtype \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(idx, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    902\u001b[0m \u001b[39mif\u001b[39;00m (dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m dtypes\u001b[39m.\u001b[39mas_dtype(dtype) \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m _SUPPORTED_SLICE_DTYPES \u001b[39mor\u001b[39;00m\n\u001b[0;32m    903\u001b[0m     idx\u001b[39m.\u001b[39mshape \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(idx\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m    904\u001b[0m   \u001b[39m# TODO(slebedev): IndexError seems more appropriate here, but it\u001b[39;00m\n\u001b[0;32m    905\u001b[0m   \u001b[39m# will break `_slice_helper` contract.\u001b[39;00m\n\u001b[1;32m--> 906\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(_SLICE_TYPE_ERROR \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m, got \u001b[39m\u001b[39m{!r}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(idx))\n",
      "\u001b[1;31mTypeError\u001b[0m: Only integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got array([195,  38,  87, 268,  81, 379, 486, 178, 418, 493, 114,  90, 152,\n       146, 405, 191, 453, 108, 480, 222, 465,  52,  59,  86, 351, 291,\n        10,  14, 369,  88, 371, 122])"
     ]
    }
   ],
   "source": [
    "# Crear instancias de las clases DataGenerator y Trainer\n",
    "data_generator = DataIterator(x, y, batch_size=32)\n",
    "trainer = Trainer(loss_fn, pred, data_generator)\n",
    "\n",
    "# Entrenar el modelo durante varias épocas\n",
    "epochs = 10\n",
    "losses, accuracies = trainer.fit(epochs)\n",
    "\n",
    "# Obtener los parámetros del modelo entrenado\n",
    "trained_w, trained_b = trainer.get_parameters()\n",
    "\n",
    "# Evaluar el modelo en un conjunto de datos de prueba\n",
    "x_test = np.random.randn(100, 2)\n",
    "y_test = np.random.randint(0, 2, (100, 1))\n",
    "loss, accuracy = trainer.evaluate(x_test, y_test)\n",
    "\n",
    "# Realizar predicciones utilizando el modelo entrenado\n",
    "x_pred = np.random.randn(10, 2)\n",
    "predictions = trainer.predict(x_pred)\n",
    "\n",
    "# Graficar las métricas de entrenamiento (pérdida y precisión)\n",
    "trainer.plot_metrics(losses, accuracies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NN_time_series",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
